{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_feature, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.reset_gate_params = self.get_parmas(num_feature, hidden_size, device)\n",
    "        self.update_gate_params = self.get_parmas(num_feature, hidden_size, device)\n",
    "        self.candidate_params = self.get_parmas(num_feature, hidden_size, device)\n",
    "        self.out_linear = nn.Linear(hidden_size, num_feature, device=device)\n",
    "        self.num_feature = num_feature\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "    def get_parmas(self, num_feature, hidden_size, device):\n",
    "        W_hx = torch.normal(0, 0.01, (num_feature, hidden_size), requires_grad=True, device=device)\n",
    "        W_hh = torch.normal(0, 0.01, (hidden_size, hidden_size), requires_grad=True, device=device)\n",
    "        b_x = torch.zeros(hidden_size, requires_grad=True, device=device)\n",
    "        b_h = torch.zeros(hidden_size, requires_grad=True, device=device)\n",
    "        return (W_hx, W_hh, b_x, b_h)\n",
    "    \n",
    "    def params(self):\n",
    "        return self.reset_gate_params + self.update_gate_params + self.candidate_params\n",
    "    \n",
    "    def weighted_sum(self, X, H, params):\n",
    "        # X=>[batch_size, num_feature]\n",
    "        # H=>[batch_size, hidden_size]\n",
    "        # params[0]=>[num_feature, hidden_size]\n",
    "        # params[1]=>[hidden_size]\n",
    "        # params[2]=>[hidden_size, hidden_size]\n",
    "        # params[3]=>[hidden_size]\n",
    "        \n",
    "        return torch.matmul(X, params[0]) + params[2] + torch.matmul(H, params[1]) + params[3]\n",
    "\n",
    "    def forward(self, X, H): # X: [batch_size, num_step], H: [batch_size, hidden_size]\n",
    "        if H is None:\n",
    "            H = torch.zeros((X.shape[0], self.hidden_size), requires_grad=True, device=self.device)\n",
    "        else:\n",
    "            H.detach_()\n",
    "        # X => [batch_size, num_step] => [batch_size, num_step, num_feature] => [num_step, batch_size, num_feature]\n",
    "        X = F.one_hot(X, self.num_feature).type(torch.float32).permute([1, 0, 2])\n",
    "\n",
    "        # x => [batch_size, num_feature]\n",
    "        Y = []\n",
    "        for x in X:\n",
    "            reset = F.sigmoid( self.weighted_sum(x, H, self.reset_gate_params) )\n",
    "            update = F.sigmoid( self.weighted_sum(x, H, self.update_gate_params) )\n",
    "            h_candidate = F.tanh( torch.matmul(x,self.candidate_params[0]) + self.candidate_params[2] + torch.matmul(reset * H, self.candidate_params[1]) + self.candidate_params[3])\n",
    "            H = update * H + (1-update) * h_candidate\n",
    "            y = self.out_linear(H)\n",
    "            Y.append(y)\n",
    "        return torch.stack(Y, dim=0).permute([1, 0, 2]), H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:10<00:00,  3.84it/s, tensor(5.4520)] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "batch_size, num_steps, use_random_iter = 32, 35, True\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps, use_random_iter)\n",
    "epochs, lr , num_hidden, num_feature = 500, 1, 256, len(vocab)\n",
    "\n",
    "device = 'cpu'\n",
    "net = GRUModel(num_feature, num_hidden, device=device)\n",
    "updater = optim.SGD(net.params(), lr=lr)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "bar = tqdm(range(epochs))\n",
    "for epoch in bar:\n",
    "    H = None\n",
    "    for x, y in train_iter:\n",
    "        y_hat, H = net(x.to(device), H)\n",
    "        loss = criteria(y_hat.reshape(-1, num_feature), y.reshape(-1).to(device))\n",
    "        updater.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        d2l.grad_clipping(net, 1)\n",
    "        updater.step()\n",
    "\n",
    "        step += 1\n",
    "        #writer.add_scalar(\"loss\", torch.exp(loss.detach().to('cpu')).item(), step)\n",
    "        bar.set_postfix_str(str(torch.exp(loss.detach())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
