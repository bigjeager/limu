{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, is_bidirectional, device):\n",
    "        super().__init__()\n",
    "        self.emb_size = 50\n",
    "        self.emb = nn.Embedding(input_size, self.emb_size)\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=self.emb_size, hidden_size=hidden_size, \n",
    "                          batch_first=True,num_layers=num_layers,bidirectional=is_bidirectional,device=device)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, X, H=None):\n",
    "        #X = F.one_hot(X, self.input_size).type(torch.float32)\n",
    "        X = self.emb(X)\n",
    "        Y, H = self.rnn(X, H)\n",
    "        O = self.linear(Y.reshape(-1, self.hidden_size))\n",
    "        return O, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:08<00:00,  2.66it/s, tensor(1.2884)]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from d2l import torch as d2l\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "batch_size, num_steps, use_random_iter = 32, 35, True\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps, use_random_iter)\n",
    "epochs, lr , num_hidden, num_feature = 500, 0.001, 500, len(vocab)\n",
    "\n",
    "device = 'cpu'\n",
    "net = RNNModel(input_size=num_feature, hidden_size=num_hidden, \n",
    "                num_layers=2,is_bidirectional=False, device=device)\n",
    "\n",
    "updater = optim.Adam(net.parameters(), lr=lr)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "bar = tqdm(range(epochs))\n",
    "for epoch in bar:\n",
    "    H = None\n",
    "    for x, y in train_iter:\n",
    "        y_hat, _ = net(x)\n",
    "        loss = criteria(y_hat.reshape(-1, num_feature), y.reshape(-1).to(device))\n",
    "        updater.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        d2l.grad_clipping(net, 1)\n",
    "        updater.step()\n",
    "\n",
    "        step += 1\n",
    "        writer.add_scalar(\"loss\", torch.exp(loss.detach().to('cpu')).item(), step)\n",
    "        bar.set_postfix_str(str(torch.exp(loss.detach())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time machine by h g wellsithe time traveller smiled are you sure we can move freely inspace right and left we ca\n"
     ]
    }
   ],
   "source": [
    "prefix = 'the time machine'\n",
    "new_prefix = torch.tensor(vocab[[p for p in prefix]])\n",
    "\n",
    "output = [new_prefix[-1]]\n",
    "\n",
    "net.eval()\n",
    "Y, H = net(new_prefix[:-1]) #[16, 1, 5], unbatched_input\n",
    "for idx in range(100):\n",
    "    Y, H = net(output[-1].reshape(-1), H)\n",
    "    output.append(torch.argmax(Y, dim=1))\n",
    "\n",
    "print(prefix + ''.join(vocab.to_tokens(output[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['emb.weight', 'rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'rnn.weight_ih_l1', 'rnn.weight_hh_l1', 'rnn.bias_ih_l1', 'rnn.bias_hh_l1', 'linear.weight', 'linear.bias'])\n",
      "tensor([-7.0853e-03, -1.2100e-01, -2.6153e-02,  3.0991e-02, -2.1006e-02,\n",
      "         4.4128e-02, -4.9681e-02,  2.8095e-02,  1.2596e-03, -4.6422e-02,\n",
      "         4.0742e-02,  9.4246e-02,  2.4218e-02, -1.7016e-02, -6.3222e-02,\n",
      "        -3.8537e-03, -2.3097e-03,  5.7354e-02,  4.7982e-02, -7.9586e-02,\n",
      "         2.5663e-02, -5.3639e-02,  4.8687e-03,  1.0056e-02,  4.1611e-02,\n",
      "         2.7002e-02, -8.7209e-03, -7.4684e-02,  1.0778e-01, -3.5348e-02,\n",
      "        -5.5436e-02, -4.2964e-02, -7.6158e-03, -1.0479e-01,  1.4320e-02,\n",
      "        -2.0866e-02,  1.8573e-02,  1.4275e-01,  2.1370e-02, -3.8222e-02,\n",
      "         5.2647e-02,  6.3794e-02, -9.9914e-02,  8.8622e-02, -3.6916e-02,\n",
      "        -6.0078e-02,  5.8160e-02,  8.4744e-03,  9.7092e-02, -5.5710e-02,\n",
      "        -3.5376e-02,  1.1966e-02, -6.8065e-02, -2.3710e-03,  1.3879e-03,\n",
      "         3.3530e-02,  5.2262e-02, -4.8536e-02,  7.2514e-02, -3.3190e-02,\n",
      "        -2.4692e-02, -1.6182e-02,  1.2403e-01,  1.0134e-01,  4.9731e-02,\n",
      "         8.5660e-02,  4.5528e-02,  2.5822e-02, -4.6953e-02, -4.3790e-02,\n",
      "        -4.9045e-02, -7.9963e-02,  3.4933e-02,  3.0292e-03, -2.5165e-02,\n",
      "         7.5737e-02, -1.0542e-01, -2.3767e-02, -1.0277e-01, -1.8086e-01,\n",
      "         3.7653e-02,  6.2528e-02, -5.6153e-02, -7.4602e-02,  4.3733e-02,\n",
      "        -5.1098e-02, -3.9711e-02,  5.1446e-02,  6.9496e-02, -2.6921e-02,\n",
      "        -2.8588e-02,  5.9529e-02,  2.4356e-02,  4.4667e-02, -1.2906e-01,\n",
      "         3.9776e-02,  6.9625e-02, -9.8716e-02, -4.8755e-02, -2.0798e-02,\n",
      "        -4.8434e-02, -1.0488e-01, -5.2100e-03,  5.6587e-02,  1.6110e-02,\n",
      "        -4.4457e-02,  5.3933e-02, -6.2907e-02,  1.1335e-01, -1.3104e-02,\n",
      "        -4.3487e-03,  4.0270e-02,  5.9599e-02,  2.0810e-02,  2.3937e-02,\n",
      "         4.3306e-02, -3.7322e-02,  7.9141e-02, -7.0404e-02, -1.1136e-01,\n",
      "         3.0358e-02,  1.2053e-02,  4.5871e-02, -1.3259e-01, -7.9969e-02,\n",
      "         4.6451e-02, -2.6521e-02, -2.7450e-02, -8.9531e-03,  3.1398e-02,\n",
      "         1.7520e-02,  8.8257e-02,  8.5380e-02, -1.1838e-01, -9.4486e-02,\n",
      "         1.4752e-02, -1.1340e-02, -5.5251e-02, -1.3239e-03,  3.6603e-02,\n",
      "        -8.2063e-03,  2.9737e-02, -6.4339e-02,  5.2442e-02, -3.6157e-02,\n",
      "         5.8365e-02,  9.7346e-02,  1.0413e-02, -7.9101e-03, -6.3819e-02,\n",
      "        -4.8126e-02, -6.6704e-02,  1.2825e-03,  1.2784e-02, -6.9359e-02,\n",
      "        -6.7888e-03,  2.0244e-02,  1.9769e-03, -9.1263e-02, -2.9140e-02,\n",
      "         1.9056e-02,  1.2869e-02, -9.2276e-02,  3.0520e-02, -9.2399e-02,\n",
      "        -7.0143e-02,  3.5166e-02, -7.8130e-02, -3.9267e-02, -1.1780e-02,\n",
      "         2.7734e-02, -1.0191e-01,  2.7704e-02, -4.3453e-02,  2.6638e-02,\n",
      "        -6.6839e-03, -7.0896e-02, -5.7055e-02,  9.3773e-02, -5.7448e-02,\n",
      "         6.4757e-02, -3.2979e-02,  1.0782e-01, -9.3777e-03, -4.6451e-02,\n",
      "         9.4126e-02,  7.2835e-02,  2.4127e-02, -1.1348e-01, -1.9562e-02,\n",
      "         1.9000e-02, -6.8686e-02,  1.9011e-02,  7.2811e-03,  2.9595e-02,\n",
      "         1.2480e-02,  1.1867e-02, -6.4133e-02, -1.1126e-02, -3.2923e-02,\n",
      "         3.4850e-02,  4.5085e-02, -5.9089e-02,  8.5790e-03,  3.9331e-03,\n",
      "        -1.1919e-01, -5.5457e-03,  7.5288e-03, -6.9264e-02,  4.4134e-02,\n",
      "         2.6229e-02, -5.2569e-02,  2.2412e-02, -2.1615e-02,  1.9411e-02,\n",
      "         2.6440e-02,  2.6925e-02,  8.3073e-03, -8.7359e-03,  4.0556e-02,\n",
      "         5.8852e-02,  3.3547e-03, -5.7811e-02, -8.4283e-02, -1.1052e-01,\n",
      "        -4.2721e-02,  6.4074e-02, -2.8324e-02,  2.8069e-03,  6.1456e-02,\n",
      "        -3.9403e-02,  3.2126e-02,  7.3368e-02, -2.2324e-02, -9.3818e-02,\n",
      "        -1.0318e-01, -3.9271e-02, -2.6421e-02,  1.3640e-02,  3.3723e-03,\n",
      "         3.1242e-02,  2.6853e-02, -2.7937e-02,  6.6712e-02, -2.0862e-02,\n",
      "        -5.1407e-02,  4.6048e-02,  1.4488e-01, -2.4575e-02, -3.3505e-02,\n",
      "        -9.2890e-02,  8.8941e-02,  2.3721e-02, -6.8087e-02,  9.3282e-02,\n",
      "         2.3981e-02,  1.3065e-01, -6.4797e-02, -2.2179e-02, -8.1056e-02,\n",
      "        -1.3064e-02,  1.2998e-02,  5.9647e-02, -9.5180e-02, -5.0698e-02,\n",
      "         1.0696e-01,  4.9870e-02,  2.9674e-02, -3.8531e-02,  1.5544e-02,\n",
      "        -5.9804e-03,  9.3050e-02, -4.5400e-02, -4.0792e-02, -4.5706e-03,\n",
      "         1.4983e-02,  9.8662e-03, -1.6670e-02, -2.3220e-02, -4.3593e-02,\n",
      "         7.3528e-02,  8.7662e-02,  5.2788e-02, -9.1896e-03,  1.9347e-02,\n",
      "        -4.8793e-02, -3.1781e-02, -2.5018e-02,  5.6397e-02,  7.2377e-02,\n",
      "        -3.2161e-02, -3.1252e-02, -1.5069e-02,  6.8273e-02,  2.9657e-02,\n",
      "        -6.7651e-02, -3.8170e-02,  9.6002e-02, -2.5241e-02, -7.4636e-02,\n",
      "         7.2342e-02,  2.3573e-02, -4.6065e-02, -3.3105e-02,  4.5699e-02,\n",
      "        -1.9115e-02,  1.9190e-02,  4.5564e-02, -6.8830e-02,  3.8857e-02,\n",
      "        -1.6883e-02, -1.1006e-01, -8.0916e-03,  4.9046e-02, -5.4922e-02,\n",
      "        -6.4775e-02, -4.5727e-02,  1.8983e-02, -1.1442e-01, -7.7367e-02,\n",
      "         9.4847e-02, -2.0740e-02,  6.1491e-02,  2.8264e-02,  9.8732e-03,\n",
      "        -5.9894e-02,  9.6054e-03, -1.6544e-02,  4.2759e-02, -3.6192e-02,\n",
      "         1.9762e-02, -9.4410e-02, -1.6397e-02, -6.3420e-02, -1.0397e-01,\n",
      "        -2.7531e-02, -1.4831e-02,  3.0314e-02,  3.3927e-02,  3.9289e-02,\n",
      "         1.0890e-02,  4.7350e-02,  3.4642e-02, -3.0044e-04,  6.2979e-02,\n",
      "         2.4763e-02,  1.6065e-02, -2.8723e-02,  3.4479e-02,  3.3244e-02,\n",
      "        -2.9806e-02, -2.0417e-02,  3.4063e-02, -7.5748e-02,  3.7895e-02,\n",
      "         3.1822e-02,  5.5733e-04, -8.5807e-02,  6.6778e-02,  4.6245e-02,\n",
      "         8.5352e-03,  1.7863e-02, -4.6310e-02,  7.5886e-03,  1.6649e-02,\n",
      "         6.3439e-02, -9.5084e-02,  2.5060e-02,  2.9629e-02, -8.9000e-02,\n",
      "         3.8835e-04, -3.5490e-02, -8.8844e-02,  3.5021e-02,  2.1493e-02,\n",
      "         1.1942e-01,  1.5963e-02,  2.1898e-02,  8.1676e-02, -3.6737e-03,\n",
      "         1.4214e-04, -5.5157e-03,  2.5445e-02, -2.3874e-02, -2.2966e-02,\n",
      "         2.5842e-02,  7.6884e-02,  4.1242e-02, -8.1454e-02,  8.7899e-03,\n",
      "         8.7411e-02,  3.3899e-02, -9.7363e-02,  4.7387e-03,  1.0072e-01,\n",
      "         2.8583e-03,  2.0897e-03, -4.0212e-02, -6.1514e-02,  4.7967e-02,\n",
      "         8.2154e-02, -5.4657e-02,  9.8805e-02,  4.9519e-02,  7.3272e-02,\n",
      "         5.6160e-03,  2.3296e-02,  1.0851e-02, -7.0428e-02,  4.9394e-02,\n",
      "        -1.0258e-03,  3.2391e-02, -6.5814e-02, -7.1194e-02,  2.6135e-02,\n",
      "        -3.4109e-02,  1.3683e-02, -3.9650e-02, -6.7018e-02, -8.3325e-02,\n",
      "         2.4787e-02,  2.2401e-02, -1.0049e-02,  1.0048e-01, -9.1976e-02,\n",
      "        -5.5776e-03, -8.5819e-03,  4.2223e-02, -4.7265e-02, -1.3373e-01,\n",
      "        -1.1165e-01,  5.7224e-02, -1.1383e-01,  8.7760e-02,  4.3873e-02,\n",
      "         9.0105e-02, -3.7762e-02, -5.6755e-02,  6.7209e-02, -4.6083e-02,\n",
      "        -3.8663e-02,  1.1224e-03,  2.3116e-03, -1.1687e-01,  1.7760e-02,\n",
      "         7.0185e-02,  4.4845e-02,  1.0160e-01, -4.6905e-02, -6.0397e-02,\n",
      "        -4.6646e-02,  2.7273e-02, -8.2537e-02,  1.0816e-02, -9.1365e-02,\n",
      "         5.5223e-02,  6.8307e-02,  6.7649e-02, -1.1996e-02,  7.3481e-02,\n",
      "         1.8140e-02,  1.0179e-01, -1.4886e-02, -1.3513e-01,  8.4598e-02,\n",
      "         8.0374e-02, -5.8624e-02, -1.0469e-02,  6.2131e-02,  2.0202e-03,\n",
      "        -1.1033e-01,  7.2740e-02, -1.6763e-02, -2.5731e-02, -8.1200e-02,\n",
      "        -8.2675e-04, -3.2324e-02, -8.2736e-02,  7.4034e-02,  7.0985e-03,\n",
      "        -7.6296e-02,  4.1248e-02, -4.5888e-02,  9.3452e-02,  6.0308e-02,\n",
      "        -6.5869e-02, -2.8879e-02,  5.5300e-02, -7.8575e-02, -5.8737e-02,\n",
      "         7.3120e-02,  9.2087e-02,  2.3105e-02, -4.2350e-03, -8.6986e-03,\n",
      "         8.5170e-02, -8.4047e-02, -9.0412e-03, -2.4281e-02,  5.3859e-02])\n"
     ]
    }
   ],
   "source": [
    "#for name, weight in net.named_parameters():\n",
    "#    print(name)\n",
    "#    print(weight.requires_grad_(True))\n",
    "#    break\n",
    "\n",
    "print(net.state_dict().keys())\n",
    "\n",
    "print(net.state_dict()['rnn.bias_ih_l0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
