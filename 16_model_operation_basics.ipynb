{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myLinearNet(\n",
      "  (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define a class extends nn.Module\n",
    "class myLinearNet(nn.Module):\n",
    "    def __init__(self, in_feature, hidden, out_feature):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_feature, hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden, out_feature)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.relu(self.linear1(X))\n",
    "        return self.linear2(X)\n",
    "    \n",
    "net = myLinearNet(3, 2, 1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mySequential(\n",
      "  (0): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ") Sequential(\n",
      "  (0): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=3, out_features=2, bias=True) Linear(in_features=3, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# nn.Sequential is a special type of nn.Module\n",
    "class mySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, arg in enumerate(args):\n",
    "            name = str(idx)\n",
    "            self._modules[name] = arg\n",
    "            #same usage as self.__modules\n",
    "            #self.add_module(name, arg)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self._modules.values:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._modules[str(idx)]\n",
    "\n",
    "sq1 = mySequential(nn.Linear(3, 2), nn.ReLU(), nn.Linear(2,1))\n",
    "sq2 = nn.Sequential(nn.Linear(3, 2), nn.ReLU(), nn.Linear(2,1))\n",
    "\n",
    "print(sq1, sq2)\n",
    "print(sq1[0], sq2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_in_net(\n",
      "  (linear1): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=2, bias=True)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (linear2): mySequential(\n",
      "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): seq_in_net(\n",
      "    (linear1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=5, out_features=2, bias=True)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "    (linear2): mySequential(\n",
      "      (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# nested nn.Module\n",
    "class seq_in_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(4,5), nn.ReLU(), nn.Linear(5,2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = mySequential(nn.Linear(2,1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.linear2(self.relu(self.linear1(X)))\n",
    "    \n",
    "nest1 = seq_in_net()\n",
    "nest2 = nn.Sequential(nest1, nn.Linear(1,1))\n",
    "\n",
    "print(nest1)\n",
    "print(nest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# nested nn.Module in function\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(2,2), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    li = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        li.add_module(f'block {i}', block1())\n",
    "    return li\n",
    "\n",
    "block_net = block2()\n",
    "nested_net = nn.Sequential(nn.Linear(2,2), block_net)\n",
    "print(nested_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====parameters,named_parameters ======\n",
      "[torch.Size([2, 3]), torch.Size([2]), torch.Size([1, 2]), torch.Size([1])]\n",
      "[('0.weight', torch.Size([2, 3])), ('0.bias', torch.Size([2])), ('2.weight', torch.Size([1, 2])), ('2.bias', torch.Size([1]))]\n",
      "===== state_dict ======\n",
      "layer2 state_dict: OrderedDict([('weight', tensor([[0.2316, 0.6217]])), ('bias', tensor([-0.2668]))])\n",
      "===== weight_data ======\n",
      "layer2 weight: Parameter containing:\n",
      "tensor([[0.2316, 0.6217]], requires_grad=True)\n",
      "layer2 weight data: tensor([[0.2316, 0.6217]])\n",
      "layer2 weight data: tensor([[0.2316, 0.6217]])\n",
      "layer2 weight data: tensor([[0.2316, 0.6217]])\n"
     ]
    }
   ],
   "source": [
    "# parameters() is a parameter generator, with only name\n",
    "# named_parameters() is a parameter generator, with name and weight\n",
    "print(\"=====parameters,named_parameters ======\")\n",
    "print( [param.shape for param in sq2.parameters()] )\n",
    "print( [(name, param.shape) for name, param in sq2.named_parameters()] )\n",
    "\n",
    "# state_dict() return OrderedDict\n",
    "print(\"===== state_dict ======\")\n",
    "print(\"layer2 state_dict:\", sq2[2].state_dict())\n",
    "\n",
    "# weight data can be accessed by net.weight.data or net.state_dict()['weight']\n",
    "# net.weight return a nn.Parameter\n",
    "print(\"===== weight_data ======\")\n",
    "print(\"layer2 weight:\", sq2[2].weight)\n",
    "print(\"layer2 weight data:\",sq2[2].weight.data)\n",
    "print(\"layer2 weight data:\", sq2[2].state_dict()['weight'])\n",
    "print(\"layer2 weight data:\", sq2.state_dict()['2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# parameter share\n",
    "share = nn.Linear(3,3)\n",
    "net_share = nn.Sequential(nn.Linear(3,3), nn.ReLU(), share, share)\n",
    "print(net_share[0].weight.data == net_share[2].weight.data)\n",
    "print(net_share[2].weight.data == net_share[3].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4585,  0.6741,  1.1821],\n",
       "        [ 0.4694, -0.7802,  0.2946],\n",
       "        [-0.0970,  0.4984,  1.0811]], requires_grad=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self define nn.Linear module\n",
    "class myLinear(nn.Module):\n",
    "    def __init__(self, in_f, out_f):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter( torch.randn((in_f, out_f)) )\n",
    "        self.bias = nn.Parameter( torch.randn(out_f) )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weight.data) + self.bias.data\n",
    "\n",
    "l1 = myLinear(3,3)\n",
    "l2 = nn.Linear(3,3,dtype=torch.float32)\n",
    "l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========save tensor===========\n",
      "tensor([True, True])\n",
      "====save list of tensor=======\n",
      "tensor([True, True]) tensor([True, True])\n",
      "========save model============\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "\n",
    "print(\"========save tensor===========\")\n",
    "torch.save(x, 'x_file')\n",
    "xx = torch.load('x_file')\n",
    "print(x == xx)\n",
    "\n",
    "print(\"====save list of tensor=======\")\n",
    "torch.save([x, y], 'x_file')\n",
    "xx, yy = torch.load('x_file')\n",
    "print(x == xx, y == yy)\n",
    "\n",
    "print(\"========save model============\")\n",
    "torch.save(nest1.state_dict(), 'x_file')\n",
    "nest1_load = seq_in_net()\n",
    "nest1_load.load_state_dict(torch.load('x_file'))\n",
    "print(nest1_load.linear1[0].weight.data == nest1.linear1[0].weight.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
